{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIdMNlqUbiVM"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWIajG-0Q5SS",
        "outputId": "b5038fd9-209f-4022-ce60-8049dc425a28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-3e3dcd3579df>:4: DeprecationWarning: load_dataset is deprecated and will be removed in future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Id   ProductId          UserId                      ProfileName  \\\n",
            "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
            "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
            "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
            "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
            "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
            "\n",
            "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
            "0                     1                       1      5  1303862400   \n",
            "1                     0                       0      1  1346976000   \n",
            "2                     1                       1      4  1219017600   \n",
            "3                     3                       3      2  1307923200   \n",
            "4                     0                       0      5  1350777600   \n",
            "\n",
            "                 Summary                                               Text  \n",
            "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
            "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
            "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
            "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
            "4            Great taffy  Great taffy at a great price.  There was a wid...  \n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"arhamrumi/amazon-product-reviews\",\n",
        "    \"Reviews.csv\"\n",
        ")\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gl7mLwDTXQ9x",
        "outputId": "fb45217e-e567-4203-d551-45a1176ab988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Value counts of newly created sentiment labels:\n",
            "label\n",
            "2    443777\n",
            "0     82037\n",
            "1     42640\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def make_sentiment_label(score):\n",
        "    if score <= 2:\n",
        "        return 0  # negative\n",
        "    elif score == 3:\n",
        "        return 1  # neutral\n",
        "    else:\n",
        "        return 2  # positive\n",
        "\n",
        "df['label'] = df['Score'].apply(make_sentiment_label)\n",
        "\n",
        "print(\"\\nValue counts of newly created sentiment labels:\")\n",
        "print(df['label'].value_counts())\n",
        "\n",
        "# For convenience, rename the text column to something shorter:\n",
        "df.rename(columns={'Text': 'review_text'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFS8imSsXVQh",
        "outputId": "d445c749-d027-4099-930b-e5561ac17295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training set size: 454763\n",
            "Testing set size:  113691\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df['review_text']\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y  # ensure balanced splits\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set size: {len(X_train)}\")\n",
        "print(f\"Testing set size:  {len(X_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cicIe23zYHuv",
        "outputId": "c66bccc6-3dd5-4ec8-b84e-50461e943b2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===TRAINING DATASET===\n",
            "Number of negative reviews: 65630\n",
            "Number of neutral reviews:  34112\n",
            "Number of positive reviews: 355021\n",
            "\n",
            "===TESTING DATASET===\n",
            "Number of negative reviews: 16407\n",
            "Number of neutral reviews:  8528\n",
            "Number of positive reviews: 88756\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_counts = pd.Series(y_train).value_counts().sort_index()\n",
        "test_counts = pd.Series(y_test).value_counts().sort_index()\n",
        "print(\"\\n===TRAINING DATASET===\")\n",
        "print(f\"Number of negative reviews: {train_counts.get(0,0)}\")\n",
        "print(f\"Number of neutral reviews:  {train_counts.get(1,0)}\")\n",
        "print(f\"Number of positive reviews: {train_counts.get(2,0)}\")\n",
        "\n",
        "print(\"\\n===TESTING DATASET===\")\n",
        "print(f\"Number of negative reviews: {test_counts.get(0,0)}\")\n",
        "print(f\"Number of neutral reviews:  {test_counts.get(1,0)}\")\n",
        "print(f\"Number of positive reviews: {test_counts.get(2,0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uLrIx4c4XqhZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "train_sentences = X_train.to_numpy()\n",
        "val_sentences   = X_test.to_numpy()\n",
        "\n",
        "train_labels = y_train.to_numpy()\n",
        "val_labels   = y_test.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0F5reZJvbp0r"
      },
      "source": [
        "# Converting Text into Numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRCXmIn8bt3j"
      },
      "source": [
        "## Text vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Cs7h88ieYfuA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "max_vocab_length = 10000  # limit vocabulary\n",
        "max_length = 50           # truncate/pad reviews to 50 tokens (adjust as needed)\n",
        "\n",
        "text_vectorizer = layers.TextVectorization(\n",
        "    max_tokens=max_vocab_length,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YoVY-iPnY3Nn"
      },
      "outputs": [],
      "source": [
        "# Fit the vectorizer to our training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVxZVFfJY71g",
        "outputId": "1ba8680c-cab6-4840-e521-960e10e17f3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Vocab size (truncate to max_vocab_length): 10000\n",
            "Top 5 words: ['', '[UNK]', np.str_('the'), np.str_('i'), np.str_('and')]\n",
            "Bottom 5 words: [np.str_('unscrew'), np.str_('twang'), np.str_('thrived'), np.str_('tale'), np.str_('stave')]\n"
          ]
        }
      ],
      "source": [
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "print(\"\\nVocab size (truncate to max_vocab_length):\", len(words_in_vocab))\n",
        "print(\"Top 5 words:\", words_in_vocab[:5])\n",
        "print(\"Bottom 5 words:\", words_in_vocab[-5:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1um7tgPbziz"
      },
      "source": [
        "## Creating an Embedding using an Embedding Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UI4MxxvpZE9-"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "embedding = layers.Embedding(\n",
        "    input_dim=max_vocab_length,   # same as number of words in vocab\n",
        "    output_dim=128,              # desired embedding size\n",
        "    name=\"embedding\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "G08awb4GZORI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred, average=\"weighted\"):\n",
        "    \"\"\"\n",
        "    Returns a dictionary of accuracy, precision, recall, f1 for multi-class.\n",
        "    Uses 'precision_recall_fscore_support' from scikit-learn with the specified\n",
        "    averaging (e.g. 'weighted' or 'macro').\n",
        "    \"\"\"\n",
        "    acc = accuracy_score(y_true, y_pred) * 100\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=average)\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIVoWIHHb6xN"
      },
      "source": [
        "# Model 0: Naive Bayes (baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnw6YW9kZPlw",
        "outputId": "de61075f-7670-44e8-ad9e-b6a59db1830e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Baseline (MultinomialNB) results ===\n",
            "Accuracy: 79.78%\n",
            "{'accuracy': 79.77676333218989, 'precision': 0.7614360180287343, 'recall': 0.7977676333218988, 'f1': 0.7236049016939615}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model_0 = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer()),\n",
        "    (\"nb\",    MultinomialNB())  # by default handles multi-class\n",
        "])\n",
        "\n",
        "model_0.fit(X_train, y_train)\n",
        "baseline_acc = model_0.score(X_test, y_test)\n",
        "baseline_preds = model_0.predict(X_test)\n",
        "baseline_results = calculate_results(y_test, baseline_preds)\n",
        "print(\"\\n=== Baseline (MultinomialNB) results ===\")\n",
        "print(f\"Accuracy: {baseline_acc*100:.2f}%\")\n",
        "print(baseline_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfXp50qub9C8"
      },
      "source": [
        "# Model 1: Feed-forward Neural Network (Dense Model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "a7T2KkHtaD-d"
      },
      "outputs": [],
      "source": [
        "# Build\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)  # 3 classes\n",
        "model_1 = tf.keras.Model(inputs, outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "z210vvC6aXF0"
      },
      "outputs": [],
      "source": [
        "# Compile\n",
        "model_1.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlYKCM_hagB8",
        "outputId": "56ebe3f9-1379-43f6-af49-cd9a4be8e684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training Simple Dense model (3-class) ===\n",
            "Epoch 1/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 10ms/step - accuracy: 0.8254 - loss: 0.4769 - val_accuracy: 0.8500 - val_loss: 0.4098\n",
            "Epoch 2/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 8ms/step - accuracy: 0.8525 - loss: 0.3986 - val_accuracy: 0.8522 - val_loss: 0.4070\n",
            "Epoch 3/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 9ms/step - accuracy: 0.8555 - loss: 0.3908 - val_accuracy: 0.8529 - val_loss: 0.4063\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b6f54946c50>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit\n",
        "print(\"\\n=== Training Simple Dense model (3-class) ===\")\n",
        "# Fit\n",
        "model_1.fit(\n",
        "    train_sentences,\n",
        "    train_labels,\n",
        "    epochs=3,  # increase for better performance\n",
        "    validation_data=(val_sentences, val_labels),\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zm4uk_XzamUn",
        "outputId": "a17740a3-ef85-480e-d4e4-f457aa9957d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation accuracy: 85.29%\n"
          ]
        }
      ],
      "source": [
        "# Evaluate\n",
        "model_1_eval = model_1.evaluate(val_sentences, val_labels, verbose=0)\n",
        "print(f\"Validation accuracy: {model_1_eval[1]*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aJTiZcXax2c",
        "outputId": "bd0b733f-411a-4a7e-e1ec-57bf0ef2f434"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3553/3553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# Predict\n",
        "model_1_probas = model_1.predict(val_sentences)\n",
        "model_1_preds = tf.argmax(model_1_probas, axis=1)  # convert softmax -> int label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b9V5GgNa178",
        "outputId": "4df0d075-5416-4ac8-af01-8f17136f9c15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Simple Dense model results ===\n",
            "{'accuracy': 85.28907301369502, 'precision': 0.8330467957041239, 'recall': 0.8528907301369502, 'f1': 0.8344316281960862}\n"
          ]
        }
      ],
      "source": [
        "model_1_results = calculate_results(val_labels, model_1_preds)\n",
        "print(\"=== Simple Dense model results ===\")\n",
        "print(model_1_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dERuevtScFtj"
      },
      "source": [
        "# Model 2: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IAIPKJLnbBbF"
      },
      "outputs": [],
      "source": [
        "# Build LSTM model\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.LSTM(64)(x)\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BlM5sCR3bCMs"
      },
      "outputs": [],
      "source": [
        "# Compile Build LSTM model\n",
        "model_2.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH2EIC6-bDwr",
        "outputId": "77ca54fc-760d-477d-f73e-e07a5048b5a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training LSTM model (3-class) ===\n",
            "Epoch 1/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 17ms/step - accuracy: 0.8575 - loss: 0.3914 - val_accuracy: 0.8764 - val_loss: 0.3388\n",
            "Epoch 2/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 12ms/step - accuracy: 0.8889 - loss: 0.3046 - val_accuracy: 0.8849 - val_loss: 0.3227\n",
            "Epoch 3/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m182s\u001b[0m 13ms/step - accuracy: 0.9078 - loss: 0.2550 - val_accuracy: 0.8885 - val_loss: 0.3270\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b6fb7351e50>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\n=== Training LSTM model (3-class) ===\")\n",
        "model_2.fit(\n",
        "    train_sentences,\n",
        "    train_labels,\n",
        "    epochs=3,\n",
        "    validation_data=(val_sentences, val_labels),\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkRMB2UYbFd8",
        "outputId": "ddd26939-4a68-4337-ddb0-c43b8140dae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3553/3553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step\n",
            "=== LSTM model results ===\n",
            "{'accuracy': 88.8478419575868, 'precision': 0.8783985459700132, 'recall': 0.8884784195758679, 'f1': 0.8810600585697077}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate LSTM model\n",
        "model_2_probas = model_2.predict(val_sentences)\n",
        "model_2_preds = tf.argmax(model_2_probas, axis=1)\n",
        "model_2_results = calculate_results(val_labels, model_2_preds)\n",
        "print(\"=== LSTM model results ===\")\n",
        "print(model_2_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcwvQKbccI6O"
      },
      "source": [
        "# Model 3: GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "yWx4KzQKcULL"
      },
      "outputs": [],
      "source": [
        "# Build GRU model\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GRU(64)(x)\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_GRU_3class\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "7RL08x-cceg6"
      },
      "outputs": [],
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvOyAGsOcie7",
        "outputId": "56768a7b-2b73-4bf2-aa11-8d5b41c2321d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training GRU model (3-class) ===\n",
            "Epoch 1/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m211s\u001b[0m 15ms/step - accuracy: 0.8822 - loss: 0.3260 - val_accuracy: 0.8852 - val_loss: 0.3330\n",
            "Epoch 2/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 11ms/step - accuracy: 0.9146 - loss: 0.2395 - val_accuracy: 0.8860 - val_loss: 0.3604\n",
            "Epoch 3/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 12ms/step - accuracy: 0.9296 - loss: 0.2023 - val_accuracy: 0.8850 - val_loss: 0.3828\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b6f54af6ed0>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\n=== Training GRU model (3-class) ===\")\n",
        "model_3.fit(\n",
        "    train_sentences,\n",
        "    train_labels,\n",
        "    epochs=3,\n",
        "    validation_data=(val_sentences, val_labels),\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgIJmkz2ckks",
        "outputId": "66b7037a-727a-4308-b424-a2af3e245d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3553/3553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 5ms/step\n",
            "=== GRU model results ===\n",
            "{'accuracy': 88.4951315407552, 'precision': 0.87857816935765, 'recall': 0.884951315407552, 'f1': 0.8812088744748546}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate GRU model\n",
        "model_3_probs = model_3.predict(val_sentences)\n",
        "model_3_preds = tf.argmax(model_3_probs, axis=1)\n",
        "model_3_results = calculate_results(val_labels, model_3_preds)\n",
        "print(\"=== GRU model results ===\")\n",
        "print(model_3_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L_SC3yZcnIr"
      },
      "source": [
        "# Model 4: Bidirectonal LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ZDQDBAvKc2D6"
      },
      "outputs": [],
      "source": [
        "# Build Bidirectional LSTM\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_BiLSTM_3class\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "sohnyiI0c4-y"
      },
      "outputs": [],
      "source": [
        "# Compile Bidirectional LSTM\n",
        "model_4.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLRAGgmzc6pr",
        "outputId": "b2c999ab-e628-4af4-a875-0080e1f7e58c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training Bidirectional LSTM model (3-class) ===\n",
            "Epoch 1/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 14ms/step - accuracy: 0.8969 - loss: 0.2860 - val_accuracy: 0.8830 - val_loss: 0.3577\n",
            "Epoch 2/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m269s\u001b[0m 15ms/step - accuracy: 0.9292 - loss: 0.2020 - val_accuracy: 0.8864 - val_loss: 0.3864\n",
            "Epoch 3/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 15ms/step - accuracy: 0.9419 - loss: 0.1659 - val_accuracy: 0.8856 - val_loss: 0.4371\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b6fb033c490>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\n=== Training Bidirectional LSTM model (3-class) ===\")\n",
        "model_4.fit(\n",
        "    train_sentences,\n",
        "    train_labels,\n",
        "    epochs=3,\n",
        "    validation_data=(val_sentences, val_labels),\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xm94swIldCn6",
        "outputId": "26fad78f-67e2-41b8-a659-e9ca87d01710"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3553/3553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 8ms/step\n",
            "=== GRU model results ===\n",
            "{'accuracy': 88.56461813160233, 'precision': 0.8789715649738844, 'recall': 0.8856461813160232, 'f1': 0.8816702297604523}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Bidirectional LSTM\n",
        "model_4_probs = model_4.predict(val_sentences)\n",
        "model_4_preds = tf.argmax(model_4_probs, axis=1)\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "print(\"=== GRU model results ===\")\n",
        "print(model_4_results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvjnXAAAdGAa"
      },
      "source": [
        "# Model 5: 1D Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ziHp7YN6dHtq"
      },
      "outputs": [],
      "source": [
        "# Build Conv1D model\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_Conv1D_3class\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "f0sCQP0gdK5e"
      },
      "outputs": [],
      "source": [
        "# Compile Conv1D model\n",
        "model_5.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYG04PGLdMf5",
        "outputId": "396d09ef-1eb5-4de2-c32e-990a0018acde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Training Conv1D model (3-class) ===\n",
            "Epoch 1/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 9ms/step - accuracy: 0.8702 - loss: 0.3542 - val_accuracy: 0.8723 - val_loss: 0.3709\n",
            "Epoch 2/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 10ms/step - accuracy: 0.8996 - loss: 0.2811 - val_accuracy: 0.8794 - val_loss: 0.3754\n",
            "Epoch 3/3\n",
            "\u001b[1m14212/14212\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 10ms/step - accuracy: 0.9209 - loss: 0.2283 - val_accuracy: 0.8809 - val_loss: 0.3995\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b6f819bf790>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\n=== Training Conv1D model (3-class) ===\")\n",
        "model_5.fit(\n",
        "    train_sentences,\n",
        "    train_labels,\n",
        "    epochs=3,\n",
        "    validation_data=(val_sentences, val_labels),\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cNu-Md0dPny",
        "outputId": "0a77f906-7ca3-4957-dab4-073963c1fcb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3553/3553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step\n",
            "=== GRU model results ===\n",
            "{'accuracy': 88.08700776666579, 'precision': 0.8717259934554324, 'recall': 0.8808700776666579, 'f1': 0.8746617629572737}\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Conv1D\n",
        "model_5_probs = model_5.predict(val_sentences)\n",
        "model_5_preds = tf.argmax(model_5_probs, axis=1)\n",
        "model_5_results = calculate_results(val_labels, model_5_preds)\n",
        "print(\"=== GRU model results ===\")\n",
        "print(model_5_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trVzMmH9jII1"
      },
      "source": [
        "# Model 6: BERT (Pre-trained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "XQ9Y4u2tkrBn"
      },
      "outputs": [],
      "source": [
        "def star_label_to_triplet(label_str: str) -> int:\n",
        "    \"\"\"\n",
        "    Convert '1 star', '2 stars', etc. (from the HF pipeline)\n",
        "    into numerical sentiment label:\n",
        "       0 = negative, 1 = neutral, 2 = positive\n",
        "    \"\"\"\n",
        "    label_str = label_str.lower()  # e.g. \"4 stars\" => \"4 stars\"\n",
        "    if \"1 star\" in label_str or \"2 stars\" in label_str:\n",
        "        return 0  # negative\n",
        "    elif \"3 stars\" in label_str:\n",
        "        return 1  # neutral\n",
        "    elif \"4 stars\" in label_str or \"5 stars\" in label_str:\n",
        "        return 2  # positive\n",
        "    else:\n",
        "        # fallback (shouldn't happen if model is correct)\n",
        "        return 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEWslck4jKUg",
        "outputId": "91137964-06f2-49a0-fa3b-74769f0866fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=model_name, tokenizer=model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "ZkLFLIPCjXFd"
      },
      "outputs": [],
      "source": [
        "pred_labels = []\n",
        "true_labels = y_test.to_list()\n",
        "\n",
        "# Convert X_test to list (if it's a pandas Series)\n",
        "test_reviews = X_test.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS5Wnq1JjXoV",
        "outputId": "82dd9236-e499-4fc2-bd77-894768e897ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running inference with the pre-trained pipeline...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        }
      ],
      "source": [
        "print(\"Running inference with the pre-trained pipeline...\")\n",
        "pred_labels = []\n",
        "\n",
        "for review_text in test_reviews:\n",
        "    # Truncate at 512 tokens\n",
        "    result = sentiment_pipeline(\n",
        "        review_text,\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )[0]\n",
        "\n",
        "    # Convert \"1 star\", \"2 stars\", etc. => 0,1,2\n",
        "    label_3class = star_label_to_triplet(result['label'])\n",
        "    pred_labels.append(label_3class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqsiraPajsZ3",
        "outputId": "197f3160-9955-4ebb-f5e3-8668c7aa51f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== BERT Pretrained (Zero-Fine-Tuning) Results ===\n",
            "{'accuracy': 84.92668724877079, 'precision': 0.8790900960584925, 'recall': 0.8492668724877079, 'f1': 0.8606725943438792}\n"
          ]
        }
      ],
      "source": [
        "model_6_results = calculate_results(true_labels, pred_labels)\n",
        "print(\"\\n=== BERT Pretrained (Zero-Fine-Tuning) Results ===\")\n",
        "print(model_6_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGDP0y5OlB30"
      },
      "source": [
        "# Comparing the performance of all the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "vJ2udQPflDec",
        "outputId": "eed2687b-112e-4af1-d44e-15e5e8324022"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"all_model_results\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.293699816735921,\n        \"min\": 79.77676333218989,\n        \"max\": 88.8478419575868,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          79.77676333218989,\n          85.28907301369502,\n          88.08700776666579\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.044295032622347484,\n        \"min\": 0.7614360180287343,\n        \"max\": 0.8790900960584925,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7614360180287343,\n          0.8330467957041239,\n          0.8717259934554324\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03293699816735922,\n        \"min\": 0.7977676333218988,\n        \"max\": 0.8884784195758679,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7977676333218988,\n          0.8528907301369502,\n          0.8808700776666579\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05753103721783184,\n        \"min\": 0.7236049016939615,\n        \"max\": 0.8816702297604523,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.7236049016939615,\n          0.8344316281960862,\n          0.8746617629572737\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "all_model_results"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bc185d44-2c56-4fb3-b241-58d6753858d4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>79.776763</td>\n",
              "      <td>0.761436</td>\n",
              "      <td>0.797768</td>\n",
              "      <td>0.723605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>simple_dense</th>\n",
              "      <td>85.289073</td>\n",
              "      <td>0.833047</td>\n",
              "      <td>0.852891</td>\n",
              "      <td>0.834432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lstm</th>\n",
              "      <td>88.847842</td>\n",
              "      <td>0.878399</td>\n",
              "      <td>0.888478</td>\n",
              "      <td>0.881060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gru</th>\n",
              "      <td>88.495132</td>\n",
              "      <td>0.878578</td>\n",
              "      <td>0.884951</td>\n",
              "      <td>0.881209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bidirectional</th>\n",
              "      <td>88.564618</td>\n",
              "      <td>0.878972</td>\n",
              "      <td>0.885646</td>\n",
              "      <td>0.881670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conv1d</th>\n",
              "      <td>88.087008</td>\n",
              "      <td>0.871726</td>\n",
              "      <td>0.880870</td>\n",
              "      <td>0.874662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bert</th>\n",
              "      <td>84.926687</td>\n",
              "      <td>0.879090</td>\n",
              "      <td>0.849267</td>\n",
              "      <td>0.860673</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc185d44-2c56-4fb3-b241-58d6753858d4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bc185d44-2c56-4fb3-b241-58d6753858d4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bc185d44-2c56-4fb3-b241-58d6753858d4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-533503e1-8a0e-4c5e-a3b8-7c3d2ac6ed47\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-533503e1-8a0e-4c5e-a3b8-7c3d2ac6ed47')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-533503e1-8a0e-4c5e-a3b8-7c3d2ac6ed47 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6cbedcb8-3705-4a96-af83-10e6d86259b9\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('all_model_results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6cbedcb8-3705-4a96-af83-10e6d86259b9 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('all_model_results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                accuracy  precision    recall        f1\n",
              "baseline       79.776763   0.761436  0.797768  0.723605\n",
              "simple_dense   85.289073   0.833047  0.852891  0.834432\n",
              "lstm           88.847842   0.878399  0.888478  0.881060\n",
              "gru            88.495132   0.878578  0.884951  0.881209\n",
              "bidirectional  88.564618   0.878972  0.885646  0.881670\n",
              "conv1d         88.087008   0.871726  0.880870  0.874662\n",
              "bert           84.926687   0.879090  0.849267  0.860673"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"simple_dense\": model_1_results,\n",
        "                                  \"lstm\": model_2_results,\n",
        "                                  \"gru\": model_3_results,\n",
        "                                  \"bidirectional\": model_4_results,\n",
        "                                  \"conv1d\": model_5_results,\n",
        "                                  \"bert\": model_6_results})\n",
        "\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "pF4yX7HNwd68"
      },
      "outputs": [],
      "source": [
        "# Save models\n",
        "import joblib\n",
        "\n",
        "joblib.dump(model_0, \"model_0.joblib\")\n",
        "model_1.save(\"model_1.keras\")\n",
        "model_2.save(\"model_2.keras\")\n",
        "model_3.save(\"model_3.keras\")\n",
        "model_4.save(\"model_4.keras\")\n",
        "model_5.save(\"model_5.keras\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
